{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":24800,"databundleVersionId":1831594,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\nimport numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Configuration\nKAGGLE_DICOM_DIR = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train/'\nANNOTATIONS_CSV = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv'\nPROCESSED_OUTPUT_DIR = '/kaggle/working/processed_images'\nTARGET_IMAGE_SIZE = (512, 512)\n\n# Create output directory\nos.makedirs(PROCESSED_OUTPUT_DIR, exist_ok=True)\n\n# Dictionary for class labels (used in visualization)\nCLASS_LABELS = {\n    0: 'Aortic enlargement', 1: 'Atelectasis', 2: 'Calcification', \n    3: 'Cardiomegaly', 4: 'Consolidation', 5: 'Edema', \n    6: 'Fibrosis', 7: 'Infiltration', 8: 'Mass', \n    9: 'Nodule', 10: 'Other lesion', 11: 'Pleural effusion', \n    12: 'Pleural thickening', 13: 'Pneumothorax', 14: 'No finding'\n}","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-11-22T09:01:32.588476Z","iopub.execute_input":"2025-11-22T09:01:32.588790Z","iopub.status.idle":"2025-11-22T09:01:32.834238Z","shell.execute_reply.started":"2025-11-22T09:01:32.588768Z","shell.execute_reply":"2025-11-22T09:01:32.833134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_dicom_image(dicom_path, output_folder, target_size):\n    \"\"\"Reads DICOM, normalizes, resizes, and saves as 8-bit PNG.\"\"\"\n    try:\n        dicom_data = pydicom.dcmread(dicom_path)\n        img = dicom_data.pixel_array\n    except Exception as e:\n        print(f\"Error reading DICOM file {os.path.basename(dicom_path)}: {e}\")\n        return None\n\n    # Normalization (Scale to 0-1)\n    img = img.astype(np.float32)\n    if img.max() > img.min():\n        img = (img - img.min()) / (img.max() - img.min())\n    else:\n        img = np.zeros_like(img, dtype=np.float32)\n\n    # Resize Image\n    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n    \n    # Scale back to 0-255 and convert to 8-bit for saving\n    img_final = (img_resized * 255).astype(np.uint8)\n    \n    # Save Image\n    base_filename = os.path.basename(dicom_path).replace('.dicom', '.png').replace('.dcm', '.png')\n    output_path = os.path.join(output_folder, base_filename)\n    \n    cv2.imwrite(output_path, img_final)\n    \n    return base_filename\n\ndef parse_annotations(annotations_csv_path, processed_image_folder):\n    \"\"\"Loads annotations and links them to the path of the newly processed images.\"\"\"\n    df_annotations = pd.read_csv(annotations_csv_path)\n    \n    # Create the filename column based on 'image_id'\n    df_annotations['image_filename'] = df_annotations['image_id'] + '.png' \n\n    # Add the full path to the processed image\n    df_annotations['image_path'] = df_annotations['image_filename'].apply(\n        lambda x: os.path.join(processed_image_folder, x)\n    )\n    \n    # Filter to keep only the entries where the processed image exists\n    df_model_input = df_annotations[df_annotations['image_path'].apply(os.path.exists)]\n    \n    return df_model_input.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T09:01:37.857335Z","iopub.execute_input":"2025-11-22T09:01:37.857653Z","iopub.status.idle":"2025-11-22T09:01:37.868524Z","shell.execute_reply.started":"2025-11-22T09:01:37.857629Z","shell.execute_reply":"2025-11-22T09:01:37.867059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random # <--- Make sure this is imported at the top of your notebook\n\n# --- Execute Preprocessing and Create df_model_input (Step 3 Revised) ---\n\n# Get a list of all DICOM files\ndicom_files_all = [os.path.join(KAGGLE_DICOM_DIR, f) \n                   for f in os.listdir(KAGGLE_DICOM_DIR) \n                   if f.lower().endswith(('.dicom', '.dcm'))]\n\ntotal_files = len(dicom_files_all)\nSAMPLE_SIZE = 1000\n\nprint(f\"Found {total_files} total DICOM files.\")\n\n# 1. Randomly sample 1000 files\nif total_files > SAMPLE_SIZE:\n    dicom_files_sampled = random.sample(dicom_files_all, SAMPLE_SIZE)\nelse:\n    dicom_files_sampled = dicom_files_all\n    \nprint(f\"Selecting {len(dicom_files_sampled)} files for processing.\")\nprint(f\"Starting conversion and resizing to {TARGET_IMAGE_SIZE}...\")\n\nprocessed_count = 0\n# 2. Process the sampled list\nfor i, dicom_path in enumerate(dicom_files_sampled):\n    result = preprocess_dicom_image(dicom_path, PROCESSED_OUTPUT_DIR, TARGET_IMAGE_SIZE)\n    if result:\n        processed_count += 1\n        \n    if (i + 1) % 100 == 0: # Check progress every 100 files since the sample is smaller\n        print(f\"Processed {i + 1} files...\")\n\nprint(f\"Finished processing! Successfully converted {processed_count} images to PNG.\")\n\n# Create the df_model_input DataFrame\n# This step automatically filters the annotations to match the processed PNG files.\ndf_model_input = parse_annotations(ANNOTATIONS_CSV, PROCESSED_OUTPUT_DIR)\nprint(f\"df_model_input created with {len(df_model_input['image_id'].unique())} unique images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T09:01:41.355406Z","iopub.execute_input":"2025-11-22T09:01:41.356474Z","iopub.status.idle":"2025-11-22T09:23:22.712631Z","shell.execute_reply.started":"2025-11-22T09:01:41.356438Z","shell.execute_reply":"2025-11-22T09:23:22.710822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Step 4: Annotation Grouping (Full Consolidated Code) ---\n\n# 1. Filter out the \"No finding\" label (Class ID 14)\ndf_boxes = df_model_input[df_model_input['class_id'] != 14].copy()\n\n# 2. Define the grouping function\ndef get_all_boxes(group):\n    \"\"\"\n    Combines class_id and individual coordinate columns into a list of lists.\n    \"\"\"\n    boxes = []\n    for _, row in group.iterrows():\n        # Using the confirmed individual coordinate columns\n        xmin = row['x_min']\n        ymin = row['y_min']\n        xmax = row['x_max']\n        ymax = row['y_max']\n        \n        # Ensure coordinates are valid\n        if not np.isnan(xmin) and not np.isnan(ymin):\n            boxes.append([\n                row['class_id'], \n                float(xmin), float(ymin), \n                float(xmax), float(ymax)\n            ])\n    return boxes\n\n# 3. CREATE df_grouped (This must execute successfully)\ndf_grouped = df_boxes.groupby('image_id').apply(get_all_boxes).reset_index(name='boxes')\n\n# 4. Merge to create df_final_model (This is the line that was failing)\ndf_final_model = df_model_input[['image_id', 'image_path']].drop_duplicates().merge(\n    df_grouped, \n    on='image_id', \n    how='left' \n)\n\n# 5. Fill empty lists for images with no findings\ndf_final_model['boxes'] = df_final_model['boxes'].apply(lambda x: x if isinstance(x, list) else [])\n\nprint(\"\\n--- df_final_model created successfully ---\")\nprint(f\"Total unique images ready for model training: {len(df_final_model)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T09:26:10.022067Z","iopub.execute_input":"2025-11-22T09:26:10.023551Z","iopub.status.idle":"2025-11-22T09:26:10.399404Z","shell.execute_reply.started":"2025-11-22T09:26:10.023506Z","shell.execute_reply":"2025-11-22T09:26:10.398281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" def draw_boxes_on_image(image_path, boxes, target_size=TARGET_IMAGE_SIZE[0]):\n    \"\"\"Loads the processed image, scales the boxes, and draws them.\"\"\"\n    \n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_with_boxes = img.copy()\n    \n    # Original image size approximation for VinBigData (needed for rescaling boxes)\n    ORIGINAL_SIZE = 1024 \n    scale_factor = target_size / ORIGINAL_SIZE\n    \n    for box_data in boxes:\n        class_id = int(box_data[0])\n        xmin, ymin, xmax, ymax = box_data[1:]\n        \n        # Rescale coordinates to the 512x512 image space\n        x_min_scaled = int(xmin * scale_factor)\n        y_min_scaled = int(ymin * scale_factor)\n        x_max_scaled = int(xmax * scale_factor)\n        y_max_scaled = int(ymax * scale_factor)\n        \n        color = (100 + (class_id * 10) % 155, 100 + (class_id * 30) % 155, 100 + (class_id * 50) % 155)\n        \n        # Draw the rectangle\n        cv2.rectangle(img_with_boxes, \n                      (x_min_scaled, y_min_scaled), \n                      (x_max_scaled, y_max_scaled), \n                      color, 2)\n        \n        # Put the class label text\n        label = CLASS_LABELS.get(class_id, f'Class {class_id}')\n        cv2.putText(img_with_boxes, label, \n                    (x_min_scaled, y_min_scaled - 10), \n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n        \n    return img_with_boxes\n\n# Find the first image that has actual findings (non-empty 'boxes' list)\n# This uses the df_final_model created in the previous step.\nsample_row = df_final_model[df_final_model['boxes'].apply(len) > 0].iloc[0]\n\nsample_path = sample_row['image_path']\nsample_boxes = sample_row['boxes']\nsample_id = sample_row['image_id']\n\nprint(f\"Displaying image ID: {sample_id} with {len(sample_boxes)} findings.\")\n\n# Draw and display the image\noutput_image = draw_boxes_on_image(sample_path, sample_boxes)\n\nplt.figure(figsize=(8, 8))\nplt.imshow(output_image)\nplt.title(f'Processed X-ray ({TARGET_IMAGE_SIZE[0]}x{TARGET_IMAGE_SIZE[1]}) with Bounding Boxes')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T09:26:20.128620Z","iopub.execute_input":"2025-11-22T09:26:20.131340Z","iopub.status.idle":"2025-11-22T09:26:20.616864Z","shell.execute_reply.started":"2025-11-22T09:26:20.131237Z","shell.execute_reply":"2025-11-22T09:26:20.615277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}