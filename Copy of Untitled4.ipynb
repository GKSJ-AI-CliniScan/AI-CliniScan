{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Lv1XvUJkCE3rG8tHY_FpGYJFcbPwMtAI","timestamp":1763629342704}],"authorship_tag":"ABX9TyOjgBDWVpnvplt3ogORbasJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3fc020847413402084e9b5079a8bf52c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edfeb00cd5064fb19c7d8b97d3a34a40","IPY_MODEL_ed2a24c5ca524105bc92b185b1283771","IPY_MODEL_52990a815a0e4d4cbbf35245e5ad6ada"],"layout":"IPY_MODEL_8d8f08ae230e4ccd92d1ca17f40bb055"}},"edfeb00cd5064fb19c7d8b97d3a34a40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de1df1e7e3934f2595727d227328288e","placeholder":"​","style":"IPY_MODEL_3d2194935c7544a7b2fa491a88a18bb5","value":"100%"}},"ed2a24c5ca524105bc92b185b1283771":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_405031d03435440e8d2d670be4c4b7be","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e324eb8f4a754861848cf14c7589de5e","value":1000}},"52990a815a0e4d4cbbf35245e5ad6ada":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9e44f2f7664441abaddf0e8e094053","placeholder":"​","style":"IPY_MODEL_2f3c2ded643644bdb698b629d9a4d0a4","value":" 1000/1000 [00:21&lt;00:00, 42.59it/s]"}},"8d8f08ae230e4ccd92d1ca17f40bb055":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1df1e7e3934f2595727d227328288e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d2194935c7544a7b2fa491a88a18bb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"405031d03435440e8d2d670be4c4b7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e324eb8f4a754861848cf14c7589de5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b9e44f2f7664441abaddf0e8e094053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f3c2ded643644bdb698b629d9a4d0a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"th3rCcq2a2Vp","executionInfo":{"status":"error","timestamp":1763628192561,"user_tz":-330,"elapsed":12,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"3b897a00-4dbe-4cd5-defa-91adfcd1f3a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting robust search for 'train.csv' inside './vinbigdata_data/'...\n","--------------------------------------------------\n","FATAL ERROR: 'train.csv' not found.\n","Please ensure the Kaggle download and unzip steps were completed in Colab.\n","--------------------------------------------------\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"Could not locate the train.csv file required for labels.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3158657439.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please ensure the Kaggle download and unzip steps were completed in Colab.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not locate the train.csv file required for labels.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Could not locate the train.csv file required for labels."]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","# --- I. CONFIGURATION ---\n","# This is the directory where the Kaggle data was unzipped.\n","# Make sure this path reflects where you told the API to download the data.\n","BASE_DATA_DIR = './vinbigdata_data/'\n","\n","# The number of unique images you want to sample\n","N_SAMPLE = 1000\n","# --- End Configuration ---\n","\n","\n","# --- II. ROBUSTLY FIND AND LOAD THE train.csv FILE ---\n","target_file = 'train.csv'\n","file_path = None\n","image_dir_path = None # Will store the path to the 'train/' image folder\n","\n","print(f\"Starting robust search for '{target_file}' inside '{BASE_DATA_DIR}'...\")\n","\n","# os.walk recursively searches the directory structure\n","for root, dirs, files in os.walk(BASE_DATA_DIR):\n","    # 1. Find the CSV file\n","    if file_path is None and target_file in files:\n","        file_path = os.path.join(root, target_file)\n","        print(f\"✅ Found CSV file at: {file_path}\")\n","\n","    # 2. Find the image folder (necessary for the next preprocessing steps)\n","    if 'train' in dirs:\n","        image_dir_path = os.path.join(root, 'train')\n","        print(f\"✅ Found image directory at: {image_dir_path}\")\n","\n","    # Stop searching if both paths are found\n","    if file_path and image_dir_path:\n","        break\n","\n","\n","if file_path is None:\n","    print(\"-\" * 50)\n","    print(f\"FATAL ERROR: '{target_file}' not found.\")\n","    print(\"Please ensure the Kaggle download and unzip steps were completed in Colab.\")\n","    print(\"-\" * 50)\n","    raise FileNotFoundError(\"Could not locate the train.csv file required for labels.\")\n","\n","\n","# --- III. LOAD AND SAMPLE THE DATA ---\n","try:\n","    # Load the full training dataframe using the dynamically found path\n","    train_df_full = pd.read_csv(file_path)\n","except Exception as e:\n","    print(f\"Error reading CSV file: {e}\")\n","    raise\n","\n","# 1. Get unique Image IDs\n","unique_image_ids_full = train_df_full['image_id'].unique()\n","\n","# 2. Sample 1000 unique Image IDs\n","if len(unique_image_ids_full) >= N_SAMPLE:\n","    sampled_ids = np.random.choice(unique_image_ids_full, size=N_SAMPLE, replace=False)\n","else:\n","    sampled_ids = unique_image_ids_full\n","\n","# 3. Filter the original dataframe to include only the sampled images and their annotations\n","train_df = train_df_full[train_df_full['image_id'].isin(sampled_ids)].copy()\n","\n","print(\"-\" * 50)\n","print(f\"Original unique image count: {len(unique_image_ids_full)}\")\n","print(f\"Successfully sampled and filtered dataframe for {len(train_df['image_id'].unique())} unique images.\")\n","print(f\"Total annotation rows in subset: {len(train_df)}\")\n","\n","# --- FINAL STEP (Verification of the result) ---\n","# The filtered dataframe is named 'train_df' and the image directory path is 'image_dir_path'\n","# You would use these two variables in the subsequent preprocessing step.\n","print(f\"Variable 'train_df' is ready (sampled labels).\")\n","print(f\"Variable 'IMAGE_DIR' for preprocessing should be set to: {image_dir_path}\")"]},{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NEOukWrhcau4","executionInfo":{"status":"ok","timestamp":1763628427000,"user_tz":-330,"elapsed":5204,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"3b345567-8793-4048-fb52-435cff89f984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"9MQ98hgcci4l","executionInfo":{"status":"ok","timestamp":1763628677718,"user_tz":-330,"elapsed":221291,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"b6ab7c6c-6ace-4692-bebb-e04f48dbd165"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-7fe5787d-17cc-451d-8324-4e968cab6824\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-7fe5787d-17cc-451d-8324-4e968cab6824\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"drashtipatel23\",\"key\":\"ee37e5b7d1455576e72a78ebad9c63d7\"}'}"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Create the .kaggle directory if it doesn't exist\n","!mkdir -p ~/.kaggle\n","\n","# Copy the uploaded kaggle.json file into the .kaggle directory\n","!cp kaggle.json ~/.kaggle/\n","\n","# Set file permissions to be read/write only by the user for security\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","print(\"Kaggle API setup is complete. You can now download datasets.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDn-2OEFd1fI","executionInfo":{"status":"ok","timestamp":1763628773845,"user_tz":-330,"elapsed":343,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"8a52164d-cb64-4642-a9ce-af5bce3a3d4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Kaggle API setup is complete. You can now download datasets.\n"]}]},{"cell_type":"code","source":["# This downloads the ZIP file containing the data\n","!kaggle competitions download -c vinbigdata-chest-xray-abnormalities-detection\n","\n","# You must then unzip the file(s) into a known directory for access:\n","!unzip -q vinbigdata-chest-xray-abnormalities-detection.zip -d vinbigdata_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ontP_5_d7tB","executionInfo":{"status":"ok","timestamp":1763628797498,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"4a8858e4-70f2-461e-8b35-2b29b919451b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/data/download-all/vinbigdata-chest-xray-abnormalities-detection\n","unzip:  cannot find or open vinbigdata-chest-xray-abnormalities-detection.zip, vinbigdata-chest-xray-abnormalities-detection.zip.zip or vinbigdata-chest-xray-abnormalities-detection.zip.ZIP.\n"]}]},{"cell_type":"code","source":["# 1. DELETE THE OLD KEY\n","!rm ~/.kaggle/kaggle.json\n","\n","# 2. Upload the NEW 'kaggle.json' file\n","from google.colab import files\n","print(\"Please upload the *NEWLY DOWNLOADED* kaggle.json file now:\")\n","files.upload()\n","\n","# 3. Re-configure permissions with the new key\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"V9LV6aQGeRlK","executionInfo":{"status":"ok","timestamp":1763628902324,"user_tz":-330,"elapsed":16695,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"12ba066b-4675-4b20-9ebd-e071d0be1d1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Please upload the *NEWLY DOWNLOADED* kaggle.json file now:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-01d1cbc2-490e-427d-a144-2147da65a338\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-01d1cbc2-490e-427d-a144-2147da65a338\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle (1).json\n"]}]},{"cell_type":"code","source":["# --- Clean Up ---\n","!rm -rf vinbigdata_data\n","!rm -f vinbigdata-chest-xray-abnormalities-detection.zip\n","\n","# --- Download & Unzip ---\n","# Download the ZIP file again\n","!kaggle competitions download -c vinbigdata-chest-xray-abnormalities-detection\n","\n","# Create the target directory\n","!mkdir vinbigdata_data\n","\n","# Unzip the file quietly into the new directory\n","!unzip -q vinbigdata-chest-xray-abnormalities-detection.zip -d vinbigdata_data\n","\n","# --- Verification ---\n","print(\"\\n--- Verification of Files ---\")\n","!ls vinbigdata_data | grep train.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKMomBJIeZ2d","executionInfo":{"status":"ok","timestamp":1763628920458,"user_tz":-330,"elapsed":1028,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"a3fce1ec-c9c6-4f85-99be-0c0a7419fcb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/data/download-all/vinbigdata-chest-xray-abnormalities-detection\n","unzip:  cannot find or open vinbigdata-chest-xray-abnormalities-detection.zip, vinbigdata-chest-xray-abnormalities-detection.zip.zip or vinbigdata-chest-xray-abnormalities-detection.zip.ZIP.\n","\n","--- Verification of Files ---\n"]}]},{"cell_type":"code","source":["# --- 1. DOWNLOAD THE NEW, ACCESSIBLE DATASET ---\n","# Note: The command changes from 'competitions download' to 'datasets download'\n","!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n","\n","# --- 2. UNZIP THE NEW FILE ---\n","# The downloaded file is usually named 'chest-xray-pneumonia.zip'\n","!unzip -q chest-xray-pneumonia.zip -d chest_xray_data\n","\n","# --- 3. VERIFY PATH ---\n","# The labels are not in a CSV; they are organized by folders.\n","print(\"\\n--- NEW DATA STRUCTURE ---\")\n","!ls chest_xray_data/chest_xray/train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3x4M0QkepKW","executionInfo":{"status":"ok","timestamp":1763629069950,"user_tz":-330,"elapsed":88215,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"c9fec07b-2e02-4ab2-a568-a89c110346d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n","License(s): other\n","Downloading chest-xray-pneumonia.zip to /content\n","100% 2.29G/2.29G [00:32<00:00, 196MB/s]\n","100% 2.29G/2.29G [00:32<00:00, 76.6MB/s]\n","\n","--- NEW DATA STRUCTURE ---\n","NORMAL\tPNEUMONIA\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","from tqdm.notebook import tqdm\n","import os\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","\n","# --- CONFIGURATION ---\n","# Base directory where the new data was unzipped (e.g., './chest_xray_data/chest_xray/')\n","# The data is structured as chest_xray_data/chest_xray/train/{NORMAL, PNEUMONIA}\n","BASE_DIR = './chest_xray_data/chest_xray/'\n","TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n","\n","IMG_SIZE = 512 # Target size for standardization (Step 3/8)\n","N_SAMPLE = 1000 # Your target sample size\n","\n","# Labels are defined by the folder names\n","CLASSES = ['NORMAL', 'PNEUMONIA']\n","CLASS_MAP = {'NORMAL': 0, 'PNEUMONIA': 1}\n","# --- End Configuration ---\n","\n","X_images = []\n","y_labels = []\n","file_paths = []"],"metadata":{"id":"xeHhZv1WfIXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List all files and assign labels based on folder structure\n","for class_name in CLASSES:\n","    class_path = os.path.join(TRAIN_DIR, class_name)\n","    class_id = CLASS_MAP[class_name]\n","\n","    for file_name in os.listdir(class_path):\n","        if file_name.endswith(('.jpeg', '.jpg', '.png')): # Filter for image files\n","            file_paths.append((os.path.join(class_path, file_name), class_id))\n","\n","# Convert to DataFrame for easier sampling\n","df_paths = pd.DataFrame(file_paths, columns=['path', 'label'])\n","\n","# Ensure we sample 1000 images (500 from each class if possible, for balance)\n","df_normal = df_paths[df_paths['label'] == 0].sample(n=min(N_SAMPLE // 2, len(df_paths[df_paths['label'] == 0])), random_state=42)\n","df_pneumonia = df_paths[df_paths['label'] == 1].sample(n=min(N_SAMPLE // 2, len(df_paths[df_paths['label'] == 1])), random_state=42)\n","\n","df_sampled = pd.concat([df_normal, df_pneumonia]).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","print(f\"Sampling complete. Processing {len(df_sampled)} images (max 1000).\")\n","print(\"-\" * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BoyYkLNofKkm","executionInfo":{"status":"ok","timestamp":1763629125930,"user_tz":-330,"elapsed":10,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"5195d153-6b57-4d65-dff0-20d030a6d789"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampling complete. Processing 1000 images (max 1000).\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["def process_single_image_robust(file_path, size):\n","    \"\"\"Applies cleaning, enhancement, and standardization steps.\"\"\"\n","\n","    # 1. Load, Convert to Grayscale (Step 2)\n","    # The dataset uses JPEG, so DICOM conversion (Step 1) is not needed.\n","    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if img is None:\n","        return None\n","\n","    # 2. Crop borders (Step 7 - Simple proportional crop)\n","    h, w = img.shape\n","    crop_h = int(h * 0.05)\n","    crop_w = int(w * 0.05)\n","    img = img[crop_h:h-crop_h, crop_w:w-crop_w]\n","\n","    # 3. Light Contrast Enhancement - CLAHE Method (Step 5)\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    img = clahe.apply(img)\n","\n","    # 4. Light Denoising - Gaussian Blur (Step 6)\n","    img = cv2.GaussianBlur(img, (3, 3), 0)\n","\n","    # 5. Resize and Padding for uniform shape (Steps 3 & 8)\n","    # Resize handles the primary standardization.\n","    img = cv2.resize(img, (size, size))\n","\n","    # 6. Intensity Normalization - MinMax scaling (Step 4)\n","    img = img.astype(np.float32) / 255.0\n","\n","    return img\n","\n","print(\"Starting robust preprocessing...\")\n","\n","for index, row in tqdm(df_sampled.iterrows(), total=len(df_sampled)):\n","    processed_img = process_single_image_robust(row['path'], IMG_SIZE)\n","\n","    if processed_img is not None:\n","        X_images.append(processed_img)\n","        y_labels.append(row['label'])\n","\n","X_images = np.array(X_images)\n","y_labels = np.array(y_labels)\n","\n","# Reshape for CNN input (Adding a channel dimension for grayscale)\n","X_images = X_images.reshape(X_images.shape[0], IMG_SIZE, IMG_SIZE, 1)\n","\n","print(f\"\\nProcessed Image Array Shape: {X_images.shape}\")\n","print(f\"Processed Label Array Shape: {y_labels.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["3fc020847413402084e9b5079a8bf52c","edfeb00cd5064fb19c7d8b97d3a34a40","ed2a24c5ca524105bc92b185b1283771","52990a815a0e4d4cbbf35245e5ad6ada","8d8f08ae230e4ccd92d1ca17f40bb055","de1df1e7e3934f2595727d227328288e","3d2194935c7544a7b2fa491a88a18bb5","405031d03435440e8d2d670be4c4b7be","e324eb8f4a754861848cf14c7589de5e","4b9e44f2f7664441abaddf0e8e094053","2f3c2ded643644bdb698b629d9a4d0a4"]},"id":"_G1I2U7yfOXK","executionInfo":{"status":"ok","timestamp":1763629166005,"user_tz":-330,"elapsed":23237,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"14ecea26-5ad4-4c37-a485-e2d39afa2ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting robust preprocessing...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc020847413402084e9b5079a8bf52c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Processed Image Array Shape: (1000, 512, 512, 1)\n","Processed Label Array Shape: (1000,)\n"]}]},{"cell_type":"code","source":["# 1. Convert integer labels to categorical (one-hot encoding)\n","num_classes = len(CLASSES)\n","Y_categorical = to_categorical(y_labels, num_classes=num_classes)\n","\n","# 2. Train/Test/Val Split (Step 11)\n","# Split the data into Training and Validation sets (e.g., 80% Train, 20% Val)\n","X_train, X_val, Y_train, Y_val = train_test_split(\n","    X_images, Y_categorical, test_size=0.2, random_state=42, stratify=y_labels\n",")\n","\n","print(\"-\" * 50)\n","print(\"Data Preparation Complete:\")\n","print(f\"X_train shape: {X_train.shape}\")\n","print(f\"X_val shape:   {X_val.shape}\")\n","print(f\"Number of classes: {num_classes}\")\n","print(\"Data is ready to feed into a Neural Network.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XukXPvEZfZrO","executionInfo":{"status":"ok","timestamp":1763629182807,"user_tz":-330,"elapsed":1690,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"ee38f1b2-5f77-4b43-aa24-eae67fe82d72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------\n","Data Preparation Complete:\n","X_train shape: (800, 512, 512, 1)\n","X_val shape:   (200, 512, 512, 1)\n","Number of classes: 2\n","Data is ready to feed into a Neural Network.\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/GKSJ-AI-CliniScan/AI-CliniScan.git\n","%cd AI-CliniScan\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xE7EwSjJkP0c","executionInfo":{"status":"ok","timestamp":1763630465555,"user_tz":-330,"elapsed":6737,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"9a1ec0d6-fcf4-4710-f9e8-3bec4393599e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'AI-CliniScan'...\n","remote: Enumerating objects: 67, done.\u001b[K\n","remote: Counting objects: 100% (67/67), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 67 (delta 16), reused 18 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (67/67), 27.76 MiB | 8.50 MiB/s, done.\n","Resolving deltas: 100% (16/16), done.\n","/content/AI-CliniScan\n"]}]},{"cell_type":"code","source":["!git checkout -b DrashtiPatel\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lN6yoXd8kf9n","executionInfo":{"status":"ok","timestamp":1763630525892,"user_tz":-330,"elapsed":84,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"b41daf91-9a73-4ec1-9d71-ab0bb370aa01"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to a new branch 'DrashtiPatel'\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBtwP8ihkrDL","executionInfo":{"status":"ok","timestamp":1763630715126,"user_tz":-330,"elapsed":39435,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"a0a0f299-ef16-4ce8-c8ce-78048a2a130c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/\"\n"],"metadata":{"id":"R-drCCl_lds8","executionInfo":{"status":"ok","timestamp":1763630771010,"user_tz":-330,"elapsed":716,"user":{"displayName":"Drashti Patel","userId":"14022575148820123887"}},"outputId":"8dbc46e8-ff1d-4881-e239-9d91a9a12a9c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["'Copy of Untitled4.ipynb'   Untitled1.ipynb   Untitled3.ipynb\n"," Untitled0.ipynb\t    Untitled2.ipynb   Untitled4.ipynb\n"]}]}]}